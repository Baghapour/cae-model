{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from numpy import array,load,save,reshape,linspace,meshgrid,pi,stack,cos,sin\n",
    "from scipy.interpolate import griddata\n",
    "from matplotlib.pyplot import contourf,figure,scatter,gca,show\n",
    "from pandas import read_csv\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "Dat = \"path/to/data\"\n",
    "\n",
    "Grid = array(read_csv(join(Dat,\"an-grid.csv\")))\n",
    "Temp = load(join(Dat,\"an-temp.npy\"))\n",
    "print(Temp.max())\n",
    "\n",
    "print(Grid.shape,Temp.shape)\n",
    "\n",
    "Fig = figure(figsize=(5,5))\n",
    "\n",
    "x = Grid[:,0]\n",
    "y = Grid[:,1]\n",
    "\n",
    "eps = 1e-3\n",
    "\n",
    "rad = linspace(0.25,0.5,64)\n",
    "tet = linspace(0,2.0*pi,128)\n",
    "\n",
    "rmat,tmat = meshgrid(rad,tet)\n",
    "\n",
    "xi = 0.5 + rmat * cos(tmat)\n",
    "yi = 0.5 + rmat * sin(tmat)\n",
    "\n",
    "scatter(xi,yi)\n",
    "segs1 = stack((xi,yi), axis = 2)\n",
    "segs2 = segs1.transpose(1, 0, 2)\n",
    "gca().add_collection(LineCollection(segs1))\n",
    "gca().add_collection(LineCollection(segs2))\n",
    "show()\n",
    "\n",
    "print(xi,yi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zi = []\n",
    "for i in range(140):\n",
    "  zz = griddata((x,y),Temp[:,i],(xi,yi),method='linear',fill_value=0)\n",
    "  print(zz.max())\n",
    "  zi.append(zz)\n",
    "  print(\"Sample %d\"%i)\n",
    "\n",
    "Fig = figure(figsize=(5,5))\n",
    "\n",
    "ccf = contourf(xi,yi,zi[9],cmap=\"jet\",levels=linspace(0,1,10),vmin=0,vmax=1)\n",
    "Fig.show()\n",
    "\n",
    "Case = array(zi)\n",
    "print(Case.shape)\n",
    "\n",
    "print( \"Max Value = \",Case.max())\n",
    "\n",
    "save(join(Dat,\"an-Temp-interp2d.npy\"),Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from numpy import reshape,newaxis,where,nan,load\n",
    "Dat = \"path/tp/data\"\n",
    "\n",
    "Case = load(join(Dat,\"an-Temp-interp2d.npy\"))[:,:,:,newaxis]\n",
    "print(Case.shape)\n",
    "print(Case.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "#config = tf.compat.v1.ConfigProto(device_count={\"CPU\": 8})\n",
    "#tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "# Input Layer\n",
    "input = Input(shape=(128, 64, 1))  \n",
    "\n",
    "cs1 = 7\n",
    "cs2 = 3\n",
    "ms  = 2\n",
    "\n",
    "# Encoder Part\n",
    "x = Conv2D(64, (cs1, cs1), activation='relu', padding='same')(input)\n",
    "x = MaxPooling2D((ms, ms), padding='same')(x)\n",
    "x = Conv2D(32, (cs1, cs1), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((ms, ms), padding='same')(x)\n",
    "x = Conv2D(16, (cs2, cs2), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((ms, ms), padding='same')(x)\n",
    "x = Conv2D(16, (cs2, cs2), activation='relu', padding='same')(x)\n",
    "enc = MaxPooling2D((ms, ms), padding='same')(x)\n",
    "\n",
    "# Decoder Part\n",
    "x = Conv2D(16, (cs2, cs2), activation='relu', padding='same')(enc)\n",
    "x = UpSampling2D((ms, ms))(x)\n",
    "x = Conv2D(16, (cs2, cs2), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((ms, ms))(x)\n",
    "x = Conv2D(32, (cs1, cs1), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((ms, ms))(x)\n",
    "x = Conv2D(64, (cs1, cs1), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((ms, ms))(x)\n",
    "output = Conv2D(1, (cs1, cs1), activation='relu', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input, output)\n",
    "#autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate = 1e-3)\n",
    "\n",
    "autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "from math import pow,floor\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.0001\n",
    "\t#drop = 0.5\n",
    "\t#epochs_drop = 2500 #250\n",
    "\t#lrate = initial_lrate * pow(drop,floor((1+epoch)/epochs_drop))\n",
    "\tlrate = initial_lrate \n",
    "\treturn lrate\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoencoder.fit(Case,Case,epochs=10000,callbacks=callbacks_list,validation_data=(Case,Case))\n",
    "\n",
    "from matplotlib.pyplot import plot,xscale,yscale\n",
    "\n",
    "xscale(\"log\")\n",
    "yscale(\"log\")\n",
    "plot(hist.history[\"loss\"])\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt(\"Loss-AE-7-3.txt\",array(hist.history[\"loss\"]))\n",
    "savetxt(\"Val-Loss-AE-7-3.txt\",array(hist.history[\"val_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred = autoencoder.predict(Case)\n",
    "\n",
    "avg = 0\n",
    "for i in range(140):\n",
    "    mse = mean_squared_error(Case[i,:,:,0],pred[i,:,:,0])\n",
    "    avg += mse\n",
    "avg /=140\n",
    "print(\"AVERAGED MSE Error = %.4e\" % avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc = Case[51][:,:,0]\n",
    "yp = pred[51][:,:,0]\n",
    "print(\"Precidtion max = \",yp.max(),\", min = \",yp.min())\n",
    "print(yc.shape,yp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure,show,contourf\n",
    "Fig = figure(figsize=(5,5))\n",
    "ccf = contourf(xi,yi,yc,cmap=\"jet\",levels=linspace(0,1,10),vmin=0,vmax=1)\n",
    "Fig.show()\n",
    "\n",
    "Fig = figure(figsize=(5,5))\n",
    "ccf = contourf(xi,yi,yp,cmap=\"jet\",levels=linspace(0,1,10),vmin=0,vmax=1)\n",
    "Fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "autoencoder.save(\"AE-7-3\")\n",
    "\n",
    "a2 = load_model(\"AE-7-3\")\n",
    "\n",
    "print(a2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0b1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f293ec448fafddab3cd48a2b45f8500ea4fb6f5f93b1833bed7ffcd5d78118bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
